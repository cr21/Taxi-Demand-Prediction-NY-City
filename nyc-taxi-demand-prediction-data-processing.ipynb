{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea80b7fd",
   "metadata": {
    "papermill": {
     "duration": 0.01834,
     "end_time": "2022-04-04T03:41:25.179598",
     "exception": false,
     "start_time": "2022-04-04T03:41:25.161258",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Newyork city Taxi Demand Prediction Data Processing and modeling\n",
    "\n",
    "   Please review and visit  [NYC Taxi Demand EDA](https://www.kaggle.com/chiragtagadiya/nyc-taxi-demand-prediction-eda/edit) for Data Analysis.\n",
    "   \n",
    "   This Notebook cotains data preprocessing and Data Modeling\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ddd75b",
   "metadata": {
    "papermill": {
     "duration": 0.01512,
     "end_time": "2022-04-04T03:41:25.211228",
     "exception": false,
     "start_time": "2022-04-04T03:41:25.196108",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Features in the dataset:\n",
    "<table border=\"1\">\n",
    "        <tr>\n",
    "            <th>Field Name</th>\n",
    "            <th>Description</th>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>VendorID</td>\n",
    "            <td>\n",
    "            A code indicating the TPEP provider that provided the record.\n",
    "            <ol>\n",
    "                <li>Creative Mobile Technologies</li>\n",
    "                <li>VeriFone Inc.</li>\n",
    "            </ol>\n",
    "            </td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>tpep_pickup_datetime</td>\n",
    "            <td>The date and time when the meter was engaged.</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>tpep_dropoff_datetime</td>\n",
    "            <td>The date and time when the meter was disengaged.</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>Passenger_count</td>\n",
    "            <td>The number of passengers in the vehicle. This is a driver-entered value.</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>Trip_distance</td>\n",
    "            <td>The elapsed trip distance in miles reported by the taximeter.</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>Pickup_longitude</td>\n",
    "            <td>Longitude where the meter was engaged.</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>Pickup_latitude</td>\n",
    "            <td>Latitude where the meter was engaged.</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>RateCodeID</td>\n",
    "            <td>The final rate code in effect at the end of the trip.\n",
    "            <ol>\n",
    "                <li> Standard rate </li>\n",
    "                <li> JFK </li>\n",
    "                <li> Newark </li>\n",
    "                <li> Nassau or Westchester</li>\n",
    "                <li> Negotiated fare </li>\n",
    "                <li> Group ride</li>\n",
    "            </ol>\n",
    "            </td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>Store_and_fwd_flag</td>\n",
    "            <td>This flag indicates whether the trip record was held in vehicle memory before sending to the vendor,<br> aka “store and forward,” because the vehicle did not have a connection to the server.<br><br>\n",
    "                Y= store and forward trip<br>\n",
    "                N= not a store and forward trip<br>\n",
    "            </td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>Dropoff_longitude</td>\n",
    "            <td>Longitude where the meter was disengaged.</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>Dropoff_ latitude</td>\n",
    "            <td>Latitude where the meter was disengaged.</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>Payment_type</td>\n",
    "            <td>A numeric code signifying how the passenger paid for the trip.\n",
    "            <ol>\n",
    "                <li> Credit card </li>\n",
    "                <li> Cash </li>\n",
    "                <li> No charge </li>\n",
    "                <li> Dispute</li>\n",
    "                <li> Unknown </li>\n",
    "                <li> Voided trip</li>\n",
    "            </ol>\n",
    "            </td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>Fare_amount</td>\n",
    "            <td>The time-and-distance fare calculated by the meter.</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>Extra</td>\n",
    "            <td>Miscellaneous extras and surcharges. Currently, this only includes. the $0.50 and $1 rush hour and overnight charges.</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>MTA_tax</td>\n",
    "            <td>0.50 MTA tax that is automatically triggered based on the metered rate in use.</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>Improvement_surcharge</td>\n",
    "            <td>0.30 improvement surcharge assessed trips at the flag drop. the improvement surcharge began being levied in 2015.</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>Tip_amount</td>\n",
    "            <td>Tip amount – This field is automatically populated for credit card tips.Cash tips are not included.</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>Tolls_amount</td>\n",
    "            <td>Total amount of all tolls paid in trip.</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>Total_amount</td>\n",
    "            <td>The total amount charged to passengers. Does not include cash tips.</td>\n",
    "        </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "162961e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-04T03:41:25.256332Z",
     "iopub.status.busy": "2022-04-04T03:41:25.255337Z",
     "iopub.status.idle": "2022-04-04T03:41:27.860795Z",
     "shell.execute_reply": "2022-04-04T03:41:27.860087Z",
     "shell.execute_reply.started": "2022-04-04T03:38:30.554130Z"
    },
    "papermill": {
     "duration": 2.634544,
     "end_time": "2022-04-04T03:41:27.861014",
     "exception": false,
     "start_time": "2022-04-04T03:41:25.226470",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import dask.dataframe as dd#similar to pandas\n",
    "\n",
    "import pandas as pd#pandas to create small dataframes \n",
    "\n",
    "#!pip3 install folium\n",
    "import folium #open street map\n",
    "\n",
    "# unix time: https://www.unixtimestamp.com/\n",
    "import datetime #Convert to unix time\n",
    "\n",
    "import time #Convert to unix time\n",
    "\n",
    "import numpy as np#Do aritmetic operations on arrays\n",
    "\n",
    "# matplotlib: used to plot graphs\n",
    "import matplotlib\n",
    "# matplotlib.use('nbagg') : matplotlib uses this protocall which makes plots more user intractive like zoom in and zoom out\n",
    "matplotlib.use('nbagg')\n",
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns#Plots\n",
    "from matplotlib import rcParams#Size of plots  \n",
    "\n",
    "# this lib is used while we calculate the stight line distance between two (lat,lon) pairs in miles\n",
    "#!pip install gpxpy\n",
    "import gpxpy.geo #Get the haversine distance\n",
    "\n",
    "from sklearn.cluster import MiniBatchKMeans, KMeans#Clustering\n",
    "import math\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "\n",
    "# to install xgboost: \n",
    "# !conda install py-xgboost --yes\n",
    "#!pip3 install xgboost\n",
    "# if it didnt happen check install_xgboost.JPG\n",
    "import xgboost as xgb\n",
    "\n",
    "# to install sklearn: pip install -U scikit-learn\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd54c2de",
   "metadata": {
    "papermill": {
     "duration": 0.016567,
     "end_time": "2022-04-04T03:41:27.893737",
     "exception": false,
     "start_time": "2022-04-04T03:41:27.877170",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Data Processing Pipiline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dec77f42",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-04T03:41:27.937423Z",
     "iopub.status.busy": "2022-04-04T03:41:27.936411Z",
     "iopub.status.idle": "2022-04-04T03:41:27.939529Z",
     "shell.execute_reply": "2022-04-04T03:41:27.939996Z",
     "shell.execute_reply.started": "2022-04-04T03:38:32.632765Z"
    },
    "papermill": {
     "duration": 0.029797,
     "end_time": "2022-04-04T03:41:27.940202",
     "exception": false,
     "start_time": "2022-04-04T03:41:27.910405",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\"\"\"\n",
    "Returned Columns:\n",
    "    # 1. passenger_count\n",
    "    # 2. trip_distance\n",
    "    # 3. pickup_longitude\n",
    "    # 4. dropoff_latitude\n",
    "    # 5. dropoff_longitude\n",
    "    # 6. pickup_latitude\n",
    "    # 7. total_amount : total paid fair amount\n",
    "    # 8. trip_times :  duration of each trip\n",
    "    # 9. pickup_times : pickup time converted into unix time \n",
    "    # 10.drop times: drop time converted to unix time\n",
    "    # 11.Speed : velocity of each trip\n",
    "\"\"\"\n",
    "\n",
    "def create_dataframe_with_trip_times(df):\n",
    "    \n",
    "    duration_df = df[['tpep_pickup_datetime','tpep_dropoff_datetime']].compute()\n",
    "    # get pickup values in unix time\n",
    "    pickup_times = [convert_to_unix_timestamp(value) for value in duration_df['tpep_pickup_datetime'].values]\n",
    "    # get dropoff values in unix time\n",
    "    drop_times = [convert_to_unix_timestamp(value) for value in duration_df['tpep_dropoff_datetime'].values]\n",
    "    # drop times and pickup times devide by 60 will give minutes\n",
    "    trip_times = (np.array(drop_times) - np.array(pickup_times))/ float(60) \n",
    "    result_df = df[['passenger_count','trip_distance','pickup_longitude','pickup_latitude','dropoff_longitude','dropoff_latitude','total_amount']].compute()\n",
    "    \n",
    "    result_df['trip_times'] = trip_times\n",
    "    result_df['pickup_times'] = pickup_times\n",
    "    result_df['drop_times'] = drop_times\n",
    "    # velocity = distance/ duration\n",
    "    result_df['Speed'] = 60*(result_df['trip_distance']/result_df['trip_times'])\n",
    "    \n",
    "    return result_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf8d8df0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-04T03:41:27.976664Z",
     "iopub.status.busy": "2022-04-04T03:41:27.976015Z",
     "iopub.status.idle": "2022-04-04T03:41:27.989606Z",
     "shell.execute_reply": "2022-04-04T03:41:27.990119Z",
     "shell.execute_reply.started": "2022-04-04T03:38:32.644994Z"
    },
    "papermill": {
     "duration": 0.033948,
     "end_time": "2022-04-04T03:41:27.990343",
     "exception": false,
     "start_time": "2022-04-04T03:41:27.956395",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def remove_outliers(df):\n",
    "    print(\"Number of records in dataframe : {}\".format(df.shape[0]))\n",
    "    # remove Latitude and longitude errors and outliers\n",
    "    a = df.shape[0]\n",
    "    temp_frame = df[((df.dropoff_longitude >= -74.15) & (df.dropoff_longitude <= -73.7004) &\\\n",
    "                       (df.dropoff_latitude >= 40.5774) & (df.dropoff_latitude <= 40.9176)) & \\\n",
    "                       ((df.pickup_longitude >= -74.15) & (df.pickup_latitude >= 40.5774)& \\\n",
    "                       (df.pickup_longitude <= -73.7004) & (df.pickup_latitude <= 40.9176))]\n",
    "    b = temp_frame.shape[0]\n",
    "    print (\"Number of outlier coordinates lying outside NY boundaries:\",(a-b))\n",
    "    \n",
    "    \n",
    "    temp_frame = df[(df.trip_times > 0) & (df.trip_times < 720)]\n",
    "    c = temp_frame.shape[0]\n",
    "    print (\"Number of outliers from trip times analysis:\",(a-c))\n",
    "    \n",
    "    temp_frame = df[(df.Speed <= 65) & (df.Speed >= 0)]\n",
    "    e = temp_frame.shape[0]\n",
    "    print (\"Number of outliers from speed analysis:\",(a-e))\n",
    "    \n",
    "    temp_frame = df[(df.total_amount <1000) & (df.total_amount >0)]\n",
    "    f = temp_frame.shape[0]\n",
    "    print (\"Number of outliers from fare analysis:\",(a-f))\n",
    "\n",
    "    del temp_frame\n",
    "    \n",
    "    df = df[((df.dropoff_longitude >= -74.15) & (df.dropoff_longitude <= -73.7004) &\\\n",
    "                       (df.dropoff_latitude >= 40.5774) & (df.dropoff_latitude <= 40.9176)) & \\\n",
    "                       ((df.pickup_longitude >= -74.15) & (df.pickup_latitude >= 40.5774)& \\\n",
    "                       (df.pickup_longitude <= -73.7004) & (df.pickup_latitude <= 40.9176))]\n",
    "    \n",
    "    df = df[(df.trip_times > 0) & (df.trip_times < 720)]\n",
    "    df = df[(df.trip_distance > 0) & (df.trip_distance < 23)]\n",
    "    df = df[(df.Speed < 45.31) & (df.Speed > 0)]\n",
    "    df = df[(df.total_amount <1000) & (df.total_amount >0)]\n",
    "    \n",
    "    print (\"Total outliers removed\",a - df.shape[0])\n",
    "    print (\"---\"*50)\n",
    "    \n",
    "    return df\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e99636e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-04T03:41:28.032122Z",
     "iopub.status.busy": "2022-04-04T03:41:28.031111Z",
     "iopub.status.idle": "2022-04-04T03:41:28.034292Z",
     "shell.execute_reply": "2022-04-04T03:41:28.033610Z",
     "shell.execute_reply.started": "2022-04-04T03:38:32.662367Z"
    },
    "papermill": {
     "duration": 0.0279,
     "end_time": "2022-04-04T03:41:28.034475",
     "exception": false,
     "start_time": "2022-04-04T03:41:28.006575",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def find_regions(k, coords, frame_with_outliers_removed):\n",
    "    \"\"\"\n",
    "    Get the Cluster centroid and length of clusters, \n",
    "    Devide the NYC city into Different clusters based on number of pickups\n",
    "    \n",
    "    Parameters:\n",
    "    \n",
    "        k = number of clusters for Kmeans algorithm\n",
    "        coords =   Trip pick up location Latitude and Longitud  dataframe on which we want to clusters,\n",
    "        frame_with_outliers_removed = dataframe on which we want to fit clustering algorithm\n",
    "        \n",
    "    Returns:\n",
    "        \n",
    "        Number of region centroid\n",
    "    \n",
    "    \"\"\"\n",
    "    kmeans = MiniBatchKMeans(n_clusters=k, batch_size=10000,random_state=42).fit(coords)\n",
    "    # predict the cluster and create new feature pickup clusters\n",
    "    frame_with_outliers_removed['pickup_cluster'] = kmeans.predict(frame_with_outliers_removed[['pickup_latitude', 'pickup_longitude']])\n",
    "    cluster_centroids = kmeans.cluster_centers_\n",
    "    cluster_len = len(cluster_centroids)\n",
    "    return cluster_centroids, cluster_len\n",
    "\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa143769",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-04T03:41:28.072757Z",
     "iopub.status.busy": "2022-04-04T03:41:28.072078Z",
     "iopub.status.idle": "2022-04-04T03:41:28.082439Z",
     "shell.execute_reply": "2022-04-04T03:41:28.082977Z",
     "shell.execute_reply.started": "2022-04-04T03:38:32.674365Z"
    },
    "papermill": {
     "duration": 0.032313,
     "end_time": "2022-04-04T03:41:28.083179",
     "exception": false,
     "start_time": "2022-04-04T03:41:28.050866",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_cluster_statistics(cluser_centroids, cluster_len):\n",
    "    \n",
    "    \"\"\"\n",
    "    Get the avg number  cluster with inter-cluster distance > 2\n",
    "    Get the avg number  cluster with inter-cluster distance < 2\n",
    "    Get the minimum inter-cluster distance ( our constraint for good clustering is 0.5 miles)\n",
    "    \n",
    "    \n",
    "    \n",
    "    Parameters:\n",
    "    \n",
    "        cluser_centroids = centroid of each cluster in city\n",
    "        cluster_len =  total number of clusters\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    print(\"Choosing the cluster of size : {} \".format(cluster_len))\n",
    "    less_than_2_miles=[]\n",
    "    more_than_2_miles=[]\n",
    "    # set min_dist with some large value (1000 miles)\n",
    "    min_dist = 1000\n",
    "    for i in  range(0,cluster_len) :\n",
    "        good_points=0\n",
    "        violated_points=0\n",
    "        for j in range(0, cluster_len):\n",
    "            if i != j :\n",
    "                # movable-type.co.uk/scripts/latlong.html\n",
    "                # haversine distance\n",
    "                centroid1 = cluser_centroids[i]\n",
    "                centroid2 = cluser_centroids[j]\n",
    "                distance_bw_centroids_in_meters = gpxpy.geo.haversine_distance(centroid1[0], centroid1[1],centroid2[0], centroid2[1])\n",
    "                # haversine_distance will be in meters, so convert distance into miles  by deviding with 1.60934*1000.\n",
    "                distance_bw_centroids_in_miles = distance_bw_centroids_in_meters/(1.60934*1000)\n",
    "                min_dist = min(min_dist,distance_bw_centroids_in_miles)\n",
    "                \n",
    "                if distance_bw_centroids_in_miles <=2:\n",
    "                    good_points+=1\n",
    "                else:\n",
    "                    violated_points+=1\n",
    "                    \n",
    "        less_than_2_miles.append(good_points)\n",
    "        more_than_2_miles.append(violated_points)\n",
    "        \n",
    "    \n",
    "    print(\"Final Result After Computation:\")\n",
    "    print(\"Avg Number of cluster with in vicinity [inter-cluster distance is < 2]  : {}\".format(np.ceil(sum(less_than_2_miles)/len(less_than_2_miles))))\n",
    "    print(\"Avg Number of cluster outside  vicinity [inter-cluster distance is >  2] : {}\".format(np.ceil(sum(more_than_2_miles)/len(more_than_2_miles))))\n",
    "    print(\"Minimum inter-cluster distance : {}\".format(min_dist))\n",
    "    print(\"+\"*70)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8aba6255",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-04T03:41:28.120151Z",
     "iopub.status.busy": "2022-04-04T03:41:28.119436Z",
     "iopub.status.idle": "2022-04-04T03:41:28.127150Z",
     "shell.execute_reply": "2022-04-04T03:41:28.127667Z",
     "shell.execute_reply.started": "2022-04-04T03:38:32.688185Z"
    },
    "papermill": {
     "duration": 0.028388,
     "end_time": "2022-04-04T03:41:28.127915",
     "exception": false,
     "start_time": "2022-04-04T03:41:28.099527",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Refer:https://www.unixtimestamp.com/\n",
    "\n",
    "# 1420070400 : 2015-01-01 00:00:00 \n",
    "# 1422748800 : 2015-02-01 00:00:00 \n",
    "# 1425168000 : 2015-03-01 00:00:00\n",
    "# 1427846400 : 2015-04-01 00:00:00 \n",
    "# 1430438400 : 2015-05-01 00:00:00 \n",
    "# 1433116800 : 2015-06-01 00:00:00\n",
    "\n",
    "# 1451606400 : 2016-01-01 00:00:00 \n",
    "# 1454284800 : 2016-02-01 00:00:00 \n",
    "# 1456790400 : 2016-03-01 00:00:00\n",
    "# 1459468800 : 2016-04-01 00:00:00 \n",
    "# 1462060800 : 2016-05-01 00:00:00 \n",
    "# 1464739200 : 2016-06-01 00:00:00\n",
    "\n",
    "\n",
    "\n",
    "def add_pickup_bins(frame,month,year):\n",
    "    \"\"\"\n",
    "    Devide all the trips in 10 minute bins    \n",
    "    \"\"\"\n",
    "    unix_pickup_times=[i for i in frame['pickup_times'].values]\n",
    "    #     unix_pickup_times = [i for i in frame['pickup_times'].values]\n",
    "    # index = 0 Jan_2015 Feb_2015 Mar_2015 Apr_2015 May_2015 June_2015\n",
    "    # index = 1 Jan_2015 Feb_2015 Mar_2015 Apr_2015 May_2015 June_2015\n",
    "    \n",
    "    unix_times = [[1420070400,1422748800,1425168000,1427846400,1430438400,1433116800],\\\n",
    "                    [1451606400,1454284800,1456790400,1459468800,1462060800,1464739200]]\n",
    "    \n",
    "    start_pickup_unix = unix_times[year-2015][month-1]\n",
    "    \n",
    "    # time.mktime will return timestamp in local time \n",
    "    # we will  subtract 24 ( 4 hours = 4*60*60 = 14400 seconds = 14400/600\n",
    "    # devide by 600 for 10 minutes inverval setting) =  24 \n",
    "    # if you are in Indian standard time then correction would be + 33 ,\n",
    "    # because India is GMT +5:30, 5.30*60*60 = 19800 => 19800/600 for 10 minutes bin we get +33.\n",
    "    \n",
    "    #     ten_minute_wise_binned_unix_pickup_times = [ int((i - start_pickup_unix )/600)+33  for i in unix_pickup_times]\n",
    "    #  I am in Eastern time so no correction needed. \n",
    "    correction = 0\n",
    "    ten_minute_wise_binned_unix_pickup_times=[(int((i-start_pickup_unix)/600) + correction) for i in unix_pickup_times]\n",
    "    frame['pickup_bins']=np.array(ten_minute_wise_binned_unix_pickup_times)\n",
    "    return frame\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d19cc2e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-04T03:41:28.165566Z",
     "iopub.status.busy": "2022-04-04T03:41:28.164867Z",
     "iopub.status.idle": "2022-04-04T03:41:28.172600Z",
     "shell.execute_reply": "2022-04-04T03:41:28.173139Z",
     "shell.execute_reply.started": "2022-04-04T03:38:32.698858Z"
    },
    "papermill": {
     "duration": 0.029303,
     "end_time": "2022-04-04T03:41:28.173342",
     "exception": false,
     "start_time": "2022-04-04T03:41:28.144039",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# upto now we cleaned data and prepared data for the month 2015,\n",
    "\n",
    "# now do the same operations for months Jan, Feb, March of 2016\n",
    "\n",
    "def dataPreparation(df, kmeans,month, year, record_count ):\n",
    "    \"\"\"\n",
    "        Prepare final data.\n",
    "\n",
    "        1. get the correct column from dataframe\n",
    "        2. compute trip duration features\n",
    "        3. computer speed, unix time stamp for pickups, remove outliers\n",
    "        4. add pickup cluster for each trip\n",
    "        5. add pickup bin for each trip\n",
    "        6. groupby trip cluster, trip bin, and trip_distance \n",
    "        7. return prepared dataframe.\n",
    "    \"\"\"\n",
    "    # 1. get the correct column from dataframe 2. compute trip duration features\n",
    "    print(\"Adding Trip times for each trip \")\n",
    "    \n",
    "    df = create_dataframe_with_trip_times(df)\n",
    "    \n",
    "    # 3. computer speed, unix time stamp for pickups, remove outliers\n",
    "    print(\"Removing outliers from dataframe\")\n",
    "    \n",
    "    df = remove_outliers(df)\n",
    "    print(\"fraction of data points that remain after removing outliers\", float(len(df)/record_count))\n",
    "    \n",
    "    # 4. add pickup cluster for each trip\n",
    "    print(\"Creating Trip clusters\")\n",
    "    df['pickup_cluster'] = kmeans.predict(df[['pickup_latitude', 'pickup_longitude']])\n",
    "    \n",
    "    print(\"Adding trip in 10 minute time interval bins\")\n",
    "    # 5.add pickup bin for each trip\n",
    "    df = add_pickup_bins(df,month,year)\n",
    "    \n",
    "    print(\"Group by trip cluster and then trip bin\")\n",
    "    # 6.groupby trip cluster, trip bin, and trip_distance \n",
    "    df_groupby = df[['pickup_cluster','pickup_bins','trip_distance']].groupby(['pickup_cluster','pickup_bins']).count()\n",
    "    \n",
    "    return df_groupby, df \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2587f657",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-04T03:41:28.210236Z",
     "iopub.status.busy": "2022-04-04T03:41:28.209455Z",
     "iopub.status.idle": "2022-04-04T03:41:28.212580Z",
     "shell.execute_reply": "2022-04-04T03:41:28.213219Z",
     "shell.execute_reply.started": "2022-04-04T03:38:32.710366Z"
    },
    "papermill": {
     "duration": 0.023338,
     "end_time": "2022-04-04T03:41:28.213470",
     "exception": false,
     "start_time": "2022-04-04T03:41:28.190132",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Data files are extremely  large, more than 10 millions records\n",
    "# We already processed and saved processed file\n",
    "# So If you want to reproduce this uncomment below line\n",
    "\n",
    "# month_jan_2016 = dd.read_csv('../input/nyc-yellow-taxi-trip-data/yellow_tripdata_2016-01.csv')\n",
    "# month_feb_2016 = dd.read_csv('../input/nyc-yellow-taxi-trip-data/yellow_tripdata_2016-02.csv')\n",
    "# month_mar_2016 = dd.read_csv('../input/nyc-yellow-taxi-trip-data/yellow_tripdata_2016-03.csv')\n",
    "\n",
    "\n",
    "# jan_2016_groupby,jan_2016_frame = dataPreparation(month_jan_2016,kmeans,1,2016,len(month_jan_2016))\n",
    "\n",
    "# feb_2016_groupby,feb_2016_frame = dataPreparation(month_feb_2016,kmeans,2,2016,len(month_feb_2016))\n",
    "\n",
    "\n",
    "# mar_2016_groupby,mar_2016_frame = dataPreparation(month_mar_2016,kmeans,3,2016,len(month_mar_2016))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5cc8bc4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-04T03:38:32.721114Z",
     "iopub.status.busy": "2022-04-04T03:38:32.720723Z",
     "iopub.status.idle": "2022-04-04T03:38:32.728099Z",
     "shell.execute_reply": "2022-04-04T03:38:32.727672Z",
     "shell.execute_reply.started": "2022-04-04T03:38:32.721079Z"
    },
    "papermill": {
     "duration": 0.016573,
     "end_time": "2022-04-04T03:41:28.247154",
     "exception": false,
     "start_time": "2022-04-04T03:41:28.230581",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1050ad37",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-04T03:41:28.284375Z",
     "iopub.status.busy": "2022-04-04T03:41:28.283681Z",
     "iopub.status.idle": "2022-04-04T03:41:28.286713Z",
     "shell.execute_reply": "2022-04-04T03:41:28.287303Z",
     "shell.execute_reply.started": "2022-04-04T03:38:32.730329Z"
    },
    "papermill": {
     "duration": 0.024226,
     "end_time": "2022-04-04T03:41:28.287512",
     "exception": false,
     "start_time": "2022-04-04T03:41:28.263286",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Getting K = 35 clusters using the kmeans \n",
    "# kmeans = MiniBatchKMeans(n_clusters=35, batch_size=10000,random_state=0).fit(coords)\n",
    "# jan_month_modified['pickup_cluster'] = kmeans.predict(jan_month_modified[['pickup_latitude', 'pickup_longitude']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328a528e",
   "metadata": {
    "papermill": {
     "duration": 0.0162,
     "end_time": "2022-04-04T03:41:28.319765",
     "exception": false,
     "start_time": "2022-04-04T03:41:28.303565",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8be3cd",
   "metadata": {
    "papermill": {
     "duration": 0.015408,
     "end_time": "2022-04-04T03:41:28.351084",
     "exception": false,
     "start_time": "2022-04-04T03:41:28.335676",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 13.859089,
   "end_time": "2022-04-04T03:41:29.178381",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-04-04T03:41:15.319292",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
